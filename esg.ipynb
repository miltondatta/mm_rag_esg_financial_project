{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from yt_dlp import YoutubeDL\n",
    "import os\n",
    "#import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "from moviepy import VideoFileClip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Conversion from Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"/home/pms/llm_project/mm_rag_esg_financial_project/downloads_vdo/Invest_with_Conscience_ ESG_Investing.mp4\"\n",
    "audio_path = os.path.splitext(video_path)[0] + '.mp3'\n",
    "\n",
    "video_clip = VideoFileClip(video_path)\n",
    "video_clip.audio.write_audiofile(audio_path,codec='mp3')\n",
    "video_clip.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcriptions Generation with Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -qqq install openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pms/llm_project/mm_rag_esg_financial_project/esg/lib/python3.10/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "device = \"cude\" if torch.cuda.is_available() else \"cpu\"\n",
    "whisper_model = whisper.load_model(\"medium\",device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pms/llm_project/mm_rag_esg_financial_project/esg/lib/python3.10/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "# Initialize the AudioTranscriber\n",
    "#transcriber = AudioTranscriber(input_folder=r\"./data\")\n",
    "\n",
    "# Initialize your Whisper model\n",
    "#transcriber.whisper_model = whisper_model\n",
    "\n",
    "# Transcribe all audios in the input folder\n",
    "#for file in glob.glob(f'{os.getcwd()}/data/*.mp3'):\n",
    "transcriptions_dict = whisper_model.transcribe(\"/home/pms/llm_project/mm_rag_esg_financial_project/data/ESG_investing_complete.mp3\")\n",
    "\n",
    "#print(transcriptions_dict)\n",
    "#transcriptions_dict\n",
    "\n",
    "# for _, data in transcriptions_dict.items():\n",
    "#     #print(f\"URL: {url}\")\n",
    "#     print(f\"Audio file: {data['audio_path']}\")\n",
    "#     print(f\"Transcription: {data['transcription'][:100]}...\")  # Print first 100 characters\n",
    "#     print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" ESG, real or marketing? It's a complete fraud. Complete fraud. It's so ridiculous. Governance has been addressed. That's useful. But this idea that you're going to get a stamp that says, oh, listen, my supplier, I've offset their carbon credits and now I understand my... It's a joke. It's jargon. And I think what people are doing right now is using it as a way to, for example, if you can paint yourself as ESG, in Europe you can essentially borrow money from the ECB at negative rates. I can do you a massage now. It's a carry-trade. He doesn't want you touching him. Coronavirus. Go Chamath. Go Chamath. Hold on. But I personally believe in climate change. I know. I think we need to do something. And so the problem with ESG is it's going to take years for this... But when you hear JP Morgan yesterday say they're not going to finance fossil fuels or you hear Ed Bastien at Delta say he's going to spend $100 million, real money by the way, effectively buying carbon offsets and investing in new biofuels every year, you say... JP Morgan, by saying what they said, will be able to borrow billions of dollars from the ECB at negative rates. You think that's what that is? It's obviously what it is. It doesn't have to work. They don't need to do anything. They are now getting free money from Europe for basically being able to say this. And you don't think they would get that money otherwise? No, because Europe basically has this condition where you can issue green bonds and you can have all of this, you know, checks and balances. So that's one thing. It's going to be very important for you to really be able to diligence the supply chain all the way down to the supplier and the supplier's supplier. So when you saw Microsoft to say they're going to do, for example... These are useful statements. It's great marketing. But again, it's a lot of sizzle, no stake. I think that what we need to do is invest in actual companies that can go and count and can go and, you know, legitimize the actual impact that companies have so that you can do the right amount of carbon offsets. And then you have to have a legitimate exchange where you can actually trade them. So if you really believe in climate change, you've got to do some hard work now. By the way, Virgin Galactic is going to be throwing off a lot of carbon. Do you buy offsets? Galactica. Galactica. Yeah, we have a plan to sort of get to sustainability. You do? Why? If it's all... Because it's important. He believes it. He just said he believes it.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriptions_dict['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF Document Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pms/llm_project/mm_rag_esg_financial_project/esg/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from unstructured.partition.pdf import partition_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_report_path = \"/home/pms/llm_project/mm_rag_esg_financial_project/pdf/Bidding_Document_UWS_AGRC.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "raw_pdf_elements=partition_pdf(\n",
    "    filename=esg_report_path,\n",
    "    strategy=\"hi_res\",\n",
    "    extract_images_in_pdf=True,\n",
    "    extract_image_block_types=[\"Image\", \"Table\"],\n",
    "    extract_image_block_to_payload=False,\n",
    "    extract_image_block_output_dir=\"extracted_data\",\n",
    ")\n",
    "\n",
    "# Save the extracted data to a file\n",
    "with open(\"extracted_pdf_data.pkl\", \"wb\") as file:\n",
    "    pickle.dump(raw_pdf_elements, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"extracted_pdf_data.pkl\", \"rb\") as file:\n",
    "    loaded_pdf_elements = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_pdf_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Header=[]\n",
    "# Footer=[]\n",
    "# Title=[]\n",
    "# NarrativeText=[]\n",
    "# Text=[]\n",
    "# ListItem=[]\n",
    "# img=[]\n",
    "# tab=[]\n",
    "# for element in raw_pdf_elements:\n",
    "#   if \"unstructured.documents.elements.Header\" in str(type(element)):\n",
    "#             Header.append(str(element))\n",
    "#   elif \"unstructured.documents.elements.Footer\" in str(type(element)):\n",
    "#             Footer.append(str(element))\n",
    "#   elif \"unstructured.documents.elements.Title\" in str(type(element)):\n",
    "#             Title.append(str(element))\n",
    "#   elif \"unstructured.documents.elements.NarrativeText\" in str(type(element)):\n",
    "#             NarrativeText.append(str(element))\n",
    "#   elif \"unstructured.documents.elements.Text\" in str(type(element)):\n",
    "#             Text.append(str(element))\n",
    "#   elif \"unstructured.documents.elements.ListItem\" in str(type(element)):\n",
    "#             ListItem.append(str(element))\n",
    "#   elif \"unstructured.documents.elements.Image\" in str(type(element)):\n",
    "#             img.append(str(element))\n",
    "#   elif \"unstructured.documents.elements.Table\" in str(type(element)):\n",
    "#             tab.append(str(element))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Textual Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.documents.elements import NarrativeText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_with_metadata(raw_data, source_document):\n",
    "\n",
    "    text_data = []\n",
    "    paragraph_counters = {}\n",
    "\n",
    "    for element in raw_data:\n",
    "        if isinstance(element, NarrativeText):\n",
    "            page_number = element.metadata.page_number\n",
    "\n",
    "            if page_number not in paragraph_counters:\n",
    "                paragraph_counters[page_number] = 1\n",
    "            else:\n",
    "                paragraph_counters[page_number] += 1\n",
    "\n",
    "            paragraph_number = paragraph_counters[page_number]\n",
    "\n",
    "            text_content = element.text\n",
    "            text_data.append({\n",
    "                \"source_document\": source_document,\n",
    "                \"page_number\": page_number,\n",
    "                \"paragraph_number\": paragraph_number,\n",
    "                \"text\": text_content\n",
    "            })\n",
    "\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text = extract_text_with_metadata(loaded_pdf_elements, esg_report_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Image Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.documents.elements import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_metadata(raw_data, source_document):\n",
    "    image_data = []\n",
    "\n",
    "    for element in raw_data:\n",
    "        if isinstance(element, Image):\n",
    "            page_number = element.metadata.page_number\n",
    "            image_path = element.metadata.image_path if hasattr(element.metadata, 'image_path') else None\n",
    "\n",
    "            image_data.append({\n",
    "                \"source_document\": source_document,\n",
    "                \"page_number\": page_number,\n",
    "                \"image_path\": image_path\n",
    "            })\n",
    "\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_image_data = extract_image_metadata(raw_pdf_elements, esg_report_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images_from_metadata(extracted_image_data, images_per_row=4):\n",
    "    valid_images = [img for img in extracted_image_data if img['image_path']]\n",
    "    if not valid_images:\n",
    "        print(\"No valid image data available.\")\n",
    "        return\n",
    "\n",
    "    num_images = len(valid_images)\n",
    "    num_rows = math.ceil(num_images / images_per_row)\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, images_per_row, figsize=(20, 5*num_rows))\n",
    "    axes = axes.flatten() if num_rows > 1 else [axes]\n",
    "\n",
    "    for ax, img_data in zip(axes, valid_images):\n",
    "        try:\n",
    "            img = Image.open(img_data['image_path'])\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "            ax.set_title(f\"Page {img_data['page_number']}\", fontsize=10)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_data['image_path']}: {str(e)}\")\n",
    "            ax.text(0.5, 0.5, f\"Error loading image\\n{str(e)}\", ha='center', va='center')\n",
    "            ax.axis('off')\n",
    "\n",
    "    for ax in axes[num_images:]:\n",
    "        fig.delaxes(ax)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images_from_metadata(extracted_image_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Table Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.documents.elements import Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table_metadata(raw_data, source_document):\n",
    "    table_data = []\n",
    "\n",
    "    for element in raw_data:\n",
    "        if isinstance(element, Table):\n",
    "            page_number = element.metadata.page_number\n",
    "\n",
    "            # Extract table content as a string\n",
    "            table_content = str(element)\n",
    "\n",
    "            table_data.append({\n",
    "                \"source_document\": source_document,\n",
    "                \"page_number\": page_number,\n",
    "                \"table_content\": table_content\n",
    "            })\n",
    "\n",
    "    return table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_table_data = extract_table_metadata(raw_pdf_elements, esg_report_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# config_data = json.load(open(\"./config.json\"))\n",
    "# #MISTRALAI_API_KEY = config_data[\"MISTRAL_API_KEY\"]\n",
    "# GROQ_API_KEY = config_data[\"GROQ_API_KEY\"]\n",
    "# #os.environ[\"MISTRALAI_API_KEY\"] = MISTRALAI_API_KEY\n",
    "# os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM,BartForCausalLM\n",
    "\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,cache_dir=\"/home/pms/llm_project/mm_rag_esg_financial_project/saved_model\")\n",
    "model_bart = BartForCausalLM.from_pretrained(model_name,cache_dir=\"/home/pms/llm_project/mm_rag_esg_financial_project/saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_name = \"microsoft/layoutlmv3-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,cache_dir=\"/home/pms/llm_project/mm_rag_esg_financial_project/saved_model\")\n",
    "model_lvm = AutoModel.from_pretrained(model_name,cache_dir=\"/home/pms/llm_project/mm_rag_esg_financial_project/saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "/tmp/ipykernel_263356/610766086.py:15: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=pipe)\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "# Create a Hugging Face pipeline for the LLaVA model\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_bart,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=100,\n",
    "    truncation=True\n",
    "    #device=0  # Set this to -1 if you don't have a GPU\n",
    ")\n",
    "\n",
    "# Integrate the Hugging Face pipeline with Langchain\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x7f6090707910>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "prompt_text = \"\"\"You are an assistant tasked with summarizing text for retrieval. \\\n",
    "    These summaries will be embedded and used to retrieve the raw text elements. \\\n",
    "    Give a concise summary of the text that is well optimized for retrieval.text: {element} \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_prompt_text = \"\"\"{element}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an assistant tasked with summarizing text for retrieval.     These summaries will be embedded and used to retrieve the raw text elements.     Give a concise summary of the text that is well optimized for retrieval.text: {element} '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['element'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['element'], input_types={}, partial_variables={}, template='You are an assistant tasked with summarizing text for retrieval.     These summaries will be embedded and used to retrieve the raw text elements.     Give a concise summary of the text that is well optimized for retrieval.text: {element} '), additional_kwargs={})])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_chain = {\"element\": lambda x: x} | prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_summaries = []\n",
    "text_summaries = summarize_chain.batch(extracted_text,{\"max_concurrency\":5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text_summaries = [sub.replace(\"\"\"Human: You are an assistant tasked with summarizing text for retrieval. \\\n",
    "    These summaries will be embedded and used to retrieve the raw text elements. \\\n",
    "    Give a concise summary of the text that is well optimized for retrieval.text:\"\"\", \"\") for sub in text_summaries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text_summaries = [sub.replace(f\"\\\"\\s\", \"\") for sub in clean_text_summaries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Data Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_summarizer_prompt = \"\"\"\n",
    "As a Tender Document analyst for emerging markets investments, provide a concise and exact summary of the table contents.\n",
    "Focus on key ESG metrics (Environmental, Social, Governance) and their relevance to emerging markets.\n",
    "Highlight significant trends, comparisons, or outliers in the data. Identify any potential impacts on investment strategies or risk assessments.\n",
    "Avoid bullet points; instead, deliver a coherent, factual summary that captures the essence of the table for ESG investment decision-making.\n",
    "\n",
    "Table: {table_content}\n",
    "\n",
    "Limit your summary to 3-4 sentences, ensuring it's precise and informative for ESG analysis in emerging markets.\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
