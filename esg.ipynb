{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -qqq install yt-dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yt_dlp import YoutubeDL\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install moviepy\n",
    "#!pip install pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "from moviepy import VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_youtube_video(url, download_path='downloads_vdo/'):\n",
    "    # Create directory if it doesn't exist\n",
    "    if not os.path.exists(download_path):\n",
    "        os.makedirs(download_path)\n",
    "\n",
    "    # Download the YouTube video\n",
    "    yt = YouTube(url)\n",
    "    video = yt.streams.filter(only_video=False, file_extension='mp4').first()\n",
    "    video_path = video.download(output_path=download_path)\n",
    "\n",
    "    print(f\"Video downloaded: {video_path}\")\n",
    "    return video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_urls = [\"https://www.youtube.com/watch?v=qP1JKWBBy80\",\n",
    "                \"https://www.youtube.com/watch?v=_p58cZIHDG4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for video in video_urls:\n",
    "    #download_youtube_video(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"/home/pms/llm_project/mm_rag_esg_financial_project/downloads_vdo/Invest_with_Conscience_ ESG_Investing.mp4\"\n",
    "audio_path = os.path.splitext(video_path)[0] + '.mp3'\n",
    "\n",
    "video_clip = VideoFileClip(video_path)\n",
    "video_clip.audio.write_audiofile(audio_path,codec='mp3')\n",
    "video_clip.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class YouTubeAudioDownloader:\n",
    "#     def __init__(self, output_folder):\n",
    "#         self.output_folder = os.path.abspath(output_folder)\n",
    "#         self.audio_files_dict = {}\n",
    "\n",
    "#     def get_safe_filename(self, filename):\n",
    "#         safe_filename = re.sub(r'[^\\w\\-.]', '_', filename)\n",
    "#         safe_filename = re.sub(r'_+', '_', safe_filename)\n",
    "#         safe_filename = safe_filename[:50].strip('_')\n",
    "#         return safe_filename\n",
    "\n",
    "#     def download_audio(self, video_url):\n",
    "#         try:\n",
    "#             ydl_opts = {\n",
    "#                 'format': 'bestaudio/best',\n",
    "#                 'postprocessors': [{\n",
    "#                     'key': 'FFmpegExtractAudio',\n",
    "#                     'preferredcodec': 'mp3',\n",
    "#                     'preferredquality': '192',\n",
    "#                 }],\n",
    "#                 'outtmpl': os.path.join(self.output_folder, '%(title)s.%(ext)s'),\n",
    "#             }\n",
    "\n",
    "#             with YoutubeDL(ydl_opts) as ydl:\n",
    "#                 info = ydl.extract_info(video_url, download=True)\n",
    "#                 filename = ydl.prepare_filename(info)\n",
    "#                 base, ext = os.path.splitext(filename)\n",
    "#                 new_file = base + '.mp3'\n",
    "\n",
    "#             print(f\"Audio file downloaded: {new_file}\")\n",
    "#             self.audio_files_dict[video_url] = new_file\n",
    "#             return new_file\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error downloading audio from {video_url}: {str(e)}\")\n",
    "#             return None\n",
    "\n",
    "#     def download_multiple_audios(self, video_urls):\n",
    "#         for url in video_urls:\n",
    "#             print(f\"Processing video: {url}\")\n",
    "#             audio_file = self.download_audio(url)\n",
    "#             if audio_file is None:\n",
    "#                 print(f\"Failed to download audio from video: {url}\")\n",
    "#         return self.audio_files_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloader = YouTubeAudioDownloader(output_folder=\"./data\")\n",
    "# video_urls = [\"https://www.youtube.com/watch?v=qP1JKWBBy80\",\n",
    "#                 \"https://www.youtube.com/watch?v=_p58cZIHDG4\"]\n",
    "\n",
    "# # Download audios from multiple videos\n",
    "# audio_files = downloader.download_multiple_audios(video_urls)\n",
    "\n",
    "# print(\"Downloaded audio files:\")\n",
    "# for audio_file in audio_files:\n",
    "#     print(audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcriptions Generation with Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -qqq install openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AudioTranscriber:\n",
    "#     def __init__(self, input_folder):\n",
    "#         self.input_folder = os.path.abspath(os.path.join(os.getcwd(), input_folder))\n",
    "#         self.whisper_model = None\n",
    "#         self.transcriptions_dict = {}\n",
    "\n",
    "#     def transcribe_audio(self, audio_file):\n",
    "#         try:\n",
    "#             if not os.path.exists(audio_file):\n",
    "#                 print(f\"Audio file not found: {audio_file}\")\n",
    "#                 return None\n",
    "\n",
    "#             file_size = os.path.getsize(audio_file)\n",
    "#             if file_size == 0:\n",
    "#                 print(f\"Audio file is empty: {audio_file}\")\n",
    "#                 return None\n",
    "\n",
    "#             transcription = self.whisper_model.transcribe(audio_file)\n",
    "#             return transcription[\"text\"]\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error in transcribe_audio: {str(e)}\")\n",
    "#             return None\n",
    "\n",
    "#     def transcribe_all_audios(self, audio_files_dict):\n",
    "#         # for url, audio_path in audio_files_dict.items():\n",
    "#         #     if not audio_path.endswith('.mp3'):\n",
    "#         #         print(f\"Skipping non-mp3 file: {audio_path}\")\n",
    "#         #         continue\n",
    "\n",
    "#         transcription = self.transcribe_audio(audio_path)\n",
    "\n",
    "#         if transcription is not None:\n",
    "#             # Add to transcriptions dictionary\n",
    "#             self.transcriptions_dict = {\n",
    "#                 #'url': url,\n",
    "#                 'audio_path': audio_path,\n",
    "#                 'transcription': transcription\n",
    "#             }\n",
    "#         else:\n",
    "#             print(f\"Failed to transcribe audio: {audio_path}\")\n",
    "\n",
    "#         return self.transcriptions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pms/llm_project/mm_rag_esg_financial_project/esg/lib/python3.10/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "device = \"cude\" if torch.cuda.is_available() else \"cpu\"\n",
    "whisper_model = whisper.load_model(\"medium\",device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pms/llm_project/mm_rag_esg_financial_project/esg/lib/python3.10/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "# Initialize the AudioTranscriber\n",
    "#transcriber = AudioTranscriber(input_folder=r\"./data\")\n",
    "\n",
    "# Initialize your Whisper model\n",
    "#transcriber.whisper_model = whisper_model\n",
    "\n",
    "# Transcribe all audios in the input folder\n",
    "#for file in glob.glob(f'{os.getcwd()}/data/*.mp3'):\n",
    "transcriptions_dict = whisper_model.transcribe(\"/home/pms/llm_project/mm_rag_esg_financial_project/data/ESG_investing_complete.mp3\")\n",
    "\n",
    "#print(transcriptions_dict)\n",
    "#transcriptions_dict\n",
    "\n",
    "# for _, data in transcriptions_dict.items():\n",
    "#     #print(f\"URL: {url}\")\n",
    "#     print(f\"Audio file: {data['audio_path']}\")\n",
    "#     print(f\"Transcription: {data['transcription'][:100]}...\")  # Print first 100 characters\n",
    "#     print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" ESG, real or marketing? It's a complete fraud. Complete fraud. It's so ridiculous. Governance has been addressed. That's useful. But this idea that you're going to get a stamp that says, oh, listen, my supplier, I've offset their carbon credits and now I understand my... It's a joke. It's jargon. And I think what people are doing right now is using it as a way to, for example, if you can paint yourself as ESG, in Europe you can essentially borrow money from the ECB at negative rates. I can do you a massage now. It's a carry-trade. He doesn't want you touching him. Coronavirus. Go Chamath. Go Chamath. Hold on. But I personally believe in climate change. I know. I think we need to do something. And so the problem with ESG is it's going to take years for this... But when you hear JP Morgan yesterday say they're not going to finance fossil fuels or you hear Ed Bastien at Delta say he's going to spend $100 million, real money by the way, effectively buying carbon offsets and investing in new biofuels every year, you say... JP Morgan, by saying what they said, will be able to borrow billions of dollars from the ECB at negative rates. You think that's what that is? It's obviously what it is. It doesn't have to work. They don't need to do anything. They are now getting free money from Europe for basically being able to say this. And you don't think they would get that money otherwise? No, because Europe basically has this condition where you can issue green bonds and you can have all of this, you know, checks and balances. So that's one thing. It's going to be very important for you to really be able to diligence the supply chain all the way down to the supplier and the supplier's supplier. So when you saw Microsoft to say they're going to do, for example... These are useful statements. It's great marketing. But again, it's a lot of sizzle, no stake. I think that what we need to do is invest in actual companies that can go and count and can go and, you know, legitimize the actual impact that companies have so that you can do the right amount of carbon offsets. And then you have to have a legitimate exchange where you can actually trade them. So if you really believe in climate change, you've got to do some hard work now. By the way, Virgin Galactic is going to be throwing off a lot of carbon. Do you buy offsets? Galactica. Galactica. Yeah, we have a plan to sort of get to sustainability. You do? Why? If it's all... Because it's important. He believes it. He just said he believes it.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriptions_dict['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF Dpcument Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pms/llm_project/mm_rag_esg_financial_project/esg/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from unstructured.partition.pdf import partition_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_report_path = \"/home/pms/llm_project/mm_rag_esg_financial_project/pdf/Bidding_Document_UWS_AGRC.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pdf_elements=partition_pdf(\n",
    "    filename=\"/home/pms/llm_project/mm_rag_esg_financial_project/pdf/Bidding_Document_UWS_AGRC.pdf\",\n",
    "    strategy=\"hi_res\",\n",
    "    extract_images_in_pdf=True,\n",
    "    extract_image_block_types=[\"Image\", \"Table\"],\n",
    "    extract_image_block_to_payload=False,\n",
    "    extract_image_block_output_dir=\"extracted_data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pdf_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Header=[]\n",
    "# Footer=[]\n",
    "# Title=[]\n",
    "# NarrativeText=[]\n",
    "# Text=[]\n",
    "# ListItem=[]\n",
    "# img=[]\n",
    "# tab=[]\n",
    "# for element in raw_pdf_elements:\n",
    "#   if \"unstructured.documents.elements.Header\" in str(type(element)):\n",
    "#             Header.append(str(element))\n",
    "#   elif \"unstructured.documents.elements.Footer\" in str(type(element)):\n",
    "#             Footer.append(str(element))\n",
    "#   elif \"unstructured.documents.elements.Title\" in str(type(element)):\n",
    "#             Title.append(str(element))\n",
    "#   elif \"unstructured.documents.elements.NarrativeText\" in str(type(element)):\n",
    "#             NarrativeText.append(str(element))\n",
    "#   elif \"unstructured.documents.elements.Text\" in str(type(element)):\n",
    "#             Text.append(str(element))\n",
    "#   elif \"unstructured.documents.elements.ListItem\" in str(type(element)):\n",
    "#             ListItem.append(str(element))\n",
    "#   elif \"unstructured.documents.elements.Image\" in str(type(element)):\n",
    "#             img.append(str(element))\n",
    "#   elif \"unstructured.documents.elements.Table\" in str(type(element)):\n",
    "#             tab.append(str(element))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Textual Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.documents.elements import NarrativeText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_with_metadata(raw_data, source_document):\n",
    "\n",
    "    text_data = []\n",
    "    paragraph_counters = {}\n",
    "\n",
    "    for element in raw_data:\n",
    "        if isinstance(element, NarrativeText):\n",
    "            page_number = element.metadata.page_number\n",
    "\n",
    "            if page_number not in paragraph_counters:\n",
    "                paragraph_counters[page_number] = 1\n",
    "            else:\n",
    "                paragraph_counters[page_number] += 1\n",
    "\n",
    "            paragraph_number = paragraph_counters[page_number]\n",
    "\n",
    "            text_content = element.text\n",
    "            text_data.append({\n",
    "                \"source_document\": source_document,\n",
    "                \"page_number\": page_number,\n",
    "                \"paragraph_number\": paragraph_number,\n",
    "                \"text\": text_content\n",
    "            })\n",
    "\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text = extract_text_with_metadata(raw_pdf_elements, esg_report_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Image Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.documents.elements import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_metadata(raw_data, source_document):\n",
    "    image_data = []\n",
    "\n",
    "    for element in raw_data:\n",
    "        if isinstance(element, Image):\n",
    "            page_number = element.metadata.page_number\n",
    "            image_path = element.metadata.image_path if hasattr(element.metadata, 'image_path') else None\n",
    "\n",
    "            image_data.append({\n",
    "                \"source_document\": source_document,\n",
    "                \"page_number\": page_number,\n",
    "                \"image_path\": image_path\n",
    "            })\n",
    "\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_image_data = extract_image_metadata(raw_pdf_elements, esg_report_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images_from_metadata(extracted_image_data, images_per_row=4):\n",
    "    valid_images = [img for img in extracted_image_data if img['image_path']]\n",
    "    if not valid_images:\n",
    "        print(\"No valid image data available.\")\n",
    "        return\n",
    "\n",
    "    num_images = len(valid_images)\n",
    "    num_rows = math.ceil(num_images / images_per_row)\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, images_per_row, figsize=(20, 5*num_rows))\n",
    "    axes = axes.flatten() if num_rows > 1 else [axes]\n",
    "\n",
    "    for ax, img_data in zip(axes, valid_images):\n",
    "        try:\n",
    "            img = Image.open(img_data['image_path'])\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "            ax.set_title(f\"Page {img_data['page_number']}\", fontsize=10)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_data['image_path']}: {str(e)}\")\n",
    "            ax.text(0.5, 0.5, f\"Error loading image\\n{str(e)}\", ha='center', va='center')\n",
    "            ax.axis('off')\n",
    "\n",
    "    for ax in axes[num_images:]:\n",
    "        fig.delaxes(ax)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images_from_metadata(extracted_image_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Table Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.documents.elements import Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table_metadata(raw_data, source_document):\n",
    "    table_data = []\n",
    "\n",
    "    for element in raw_data:\n",
    "        if isinstance(element, Table):\n",
    "            page_number = element.metadata.page_number\n",
    "\n",
    "            # Extract table content as a string\n",
    "            table_content = str(element)\n",
    "\n",
    "            table_data.append({\n",
    "                \"source_document\": source_document,\n",
    "                \"page_number\": page_number,\n",
    "                \"table_content\": table_content\n",
    "            })\n",
    "\n",
    "    return table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_table_data = extract_table_metadata(raw_pdf_elements, esg_report_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "config_data = json.load(open(\"./config.json\"))\n",
    "#MISTRALAI_API_KEY = config_data[\"MISTRAL_API_KEY\"]\n",
    "GROQ_API_KEY = config_data[\"GROQ_API_KEY\"]\n",
    "#os.environ[\"MISTRALAI_API_KEY\"] = MISTRALAI_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(\n",
    "    model=\"llava-v1.5-7b-4096-preview\",\n",
    "    temperature=0.5,\n",
    "    api_key=GROQ_API_KEY,\n",
    "    max_tokens=4096,\n",
    "    max_retries=2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
